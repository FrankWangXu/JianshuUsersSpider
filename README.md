# Python 使用Scrapy框架爬取简书用户数据

> 网络爬虫的使用与开发


-------------------
 

项目概况：
-------

1.	利用网络爬虫获取简书用户的原始数据（用户在简书上阅读、点评和发布的历史数据）。
2.	以线上生产环境要求代码规范，致力于编写高可维护、通用性强的代码。


功能模块：
-------

1.	jianshu 主要爬取简书用户发表的文章。
2.	jianshuInfo 主要爬取简书用户的个人介绍。
3.	jianshuUser 主要爬取简书用户关注的专题、创建的专题以及用户自己的文集。


分析URL：
--------

先从要抓取的数据和最终页面来分析URL
    简书的用户首页的url是这样的http://www.jianshu.com/users/54b5900965ea/，即/users+ 用户ID，但是不同类型的用户看到用户首页是不一样的，同样是/users/userId进来的，发表过文章的用户的首页指向的是http://www.jianshu.com/users/54b5900965ea/latest_articles 即最新文章页面（latest_articles）, 没发表文章的用户（包括点赞、评论、粉）指向的页面是http://www.jianshu.com/users/useridxxxx/timeline，即最新动态页面（timeline）。
这两种页面上都有我们所需要的信息，左边都是个人信息+发表文章汇总数据，互动数据。如果我们要获得用户的注册时间，一共发表多少评论（这算一个用户活跃数据），这两个数据只能在timeline(最新动态)页面上获取。


Scrapy抓取Ajax数据：
-----

**简书网站很多地方采用了Ajax(异步JavaScript和XML)，大大提高了页面加载的速度。由于Ajax数据从源代码里找不到，增加了数据抓取的复杂度。使用了http://www.jianshu.com/p/1ecf087ac741 中的抓取技巧。**

数据存储：
---
最终数据存储在MongoDB中，MongoDB是最流行的NoSQL数据库，它高性能、轻量级、易于扩展，适用于移动互联网敏捷发展。

----

有梦想，有野心，至少是件好事，与其叹息世事维艰，不如拼斗一把，你会发现自己能超越很多人，至少你已经超越了那个只会自怨自艾的自己。

----------
